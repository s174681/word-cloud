library(tm)
library(wordcloud)
library(memoise)
shiny::runApp()
#A simple word cloud generator, based on [this blog #post](http://pirategrunt.com/2013/12/11/24-days-of-r-day-11/) by PirateGrunt.
runApp()
runApp()
shiny::runApp()
myCorpus = Corpus(VectorSource(text))
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt.gz", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
library("tm", lib.loc="~/R/win-library/3.4")
library("tm.plugin.alceste", lib.loc="~/R/win-library/3.4")
library("tm.plugin.dc", lib.loc="~/R/win-library/3.4")
library("tm.plugin.europresse", lib.loc="~/R/win-library/3.4")
library("tm.plugin.factiva", lib.loc="~/R/win-library/3.4")
library("tm.plugin.lexisnexis", lib.loc="~/R/win-library/3.4")
library("tm.plugin.mail", lib.loc="~/R/win-library/3.4")
library("tm.plugin.webmining", lib.loc="~/R/win-library/3.4")
library("tmap", lib.loc="~/R/win-library/3.4")
library("tmaptools", lib.loc="~/R/win-library/3.4")
library("KernSmooth", lib.loc="~/R/win-library/3.4")
library("heatmaply", lib.loc="~/R/win-library/3.4")
library("gplots", lib.loc="~/R/win-library/3.4")
library("memoise", lib.loc="~/R/win-library/3.4")
library("wordcloud2", lib.loc="~/R/win-library/3.4")
library("wordcloud", lib.loc="~/R/win-library/3.4")
shiny::runApp()
runApp()
runApp()
runApp()
books <<- list("PlikM" = "M",
"PlikN" = "N",
"PlikO" = "O")
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.zip", book),
encoding="UTF-8")
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.zip", book),
encoding="UTF-8")
}
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.zip", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, tolower)
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, PlainTextDocument)
#myCorpus = tm_map(myCorpus, removeWords,
#       c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
stopwords<-readLines("./stoplista_PL.txt",encoding = "UTF-8")
myCorpus<-tm_map(myCorpus,removeWords,stopwords)
myCorpus<-tm_map(myCorpus,stripWhitespace)
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
})
stopwords<-readLines("./stoplista_PL.txt",encoding = "UTF-8")
stopwords
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "ach", "aj", "albo"))
stopwords <- readLines("./stoplista_PL.txt",encoding = "UTF-8")
stopwords <- readLines(printf("./stoplista_PL.txt"),encoding = "UTF-8")
runApp()
stopwords <- readLines(sprintf("./stoplista_PL.txt.gz"),
encoding="UTF-8")
stopwords <- readLines(sprintf("D:/LULA/program/082-word-cloud/stoplista_PL.txt.gz"),
encoding="UTF-8")
stopwords <- readLines(sprintf("D:/LULA/program/082-word-cloud/stoplista_PL.txt.gz"), encoding="UTF-8")
runApp()
runApp()
stopwords <- readLines(sprintf("D:/LULA/program/082-word-cloud/stoplista_PL.txt.gz"), encoding="UTF-8")
stopwords
ewastoplista <- readLines(printf("./stoplista_PL.txt"),encoding = "UTF-8")
ewastoplista <- readLines(sprintf("./stoplista_PL.txt.gz"),encoding = "UTF-8")
ewastoplista
lemma <- readLines(sprintf("./lemmatization-pl.txt.gz"), encoding="UTF-8")
lemma <- tolower(lemma)
lemmat <- data.table(
lemmats = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 1)),
tolemmat = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 2))
)
library(data.table)
lemmat <- data.table(
lemmats = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 1)),
tolemmat = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 2))
)
for(i in 3280000:3296232)
{
myCorpus <- tm_map(myCorpus, (gsub),
pattern = paste("", lemmat$tolemmat[i],""),
replacement = paste("", lemmat$lemmats[i],"")
)
}
writeLines(as.character(myCorpus[[3]]))
runApp()
runApp()
shiny::runApp()
runApp()
katalog<-"D:/LULA/program/Aforyzmy/"
katalog<-"./Aforyzmy/"
katalog
docsCorpus<-VCorpus(DirSource(katalog,encoding = "UTF-8"),readerControl = list(reader=readPlain))
docsCorpus = tm_map(docsCorpus, tolower)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
library("tmap", lib.loc="~/R/win-library/3.4")
library("dendextend", lib.loc="~/R/win-library/3.4")
runApp()
library(topicmodels)
library(dendextend)
runApp()
shiny::runApp()
library("tmap", lib.loc="~/R/win-library/3.4")
install.packages("tm")
install.packages("topicmodels")
install.packages("dendextend")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
install.packages("isa2")
runApp()
install.packages("isa")
install.packages("Isa")
katalog<-"./Aforyzmy/"    #textmining_1" #forma podstawowa
docsCorpus<-VCorpus(DirSource(katalog,encoding = "UTF-8"),readerControl = list(reader=readPlain))
#docsCorpus = Corpus(VectorSource(text))
docsCorpus = tm_map(docsCorpus, tolower)
docsCorpus = tm_map(docsCorpus, removePunctuation)
docsCorpus = tm_map(docsCorpus, removeNumbers)
docsCorpus = tm_map(docsCorpus, PlainTextDocument)
#myCorpus = tm_map(docsCorpus, removeWords, c(stopwords("SMART"), "ach", "aj", "albo"))
stopwords <- readLines(sprintf("./stoplista_PL.txt.gz"),encoding = "UTF-8")
docsCorpus = tm_map(docsCorpus,removeWords,stopwords)
docsCorpus = tm_map(docsCorpus,stripWhitespace)
lemma <- readLines(sprintf("./shortlemmatization.txt.gz"), encoding="UTF-8")
lemma <- tolower(lemma)
lemmat <- data.table(
lemmats = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 1)),
tolemmat = as.character(lapply(strsplit(as.character(lemma), split="\t"), "[", 2))
)
for(i in 1:760)
{
docsCorpus <- tm_map(docsCorpus, (gsub),
pattern = paste("", lemmat$tolemmat[i],""),
replacement = paste("", lemmat$lemmats[i],"")
)
}
dtm<-DocumentTermMatrix(korpus, control = list(weighting=weightTfIdf,bounds = list(global = c(input$max))))
dtm<-DocumentTermMatrix(docsCorpus, control = list(weighting=weightTfIdf,bounds = list(global = c(input$max))))
dtm<-DocumentTermMatrix(docsCorpus, control = list(weighting=weightTfIdf,bounds = list(global = c(2,6))))
txt_mat <- as.textmatrix(t(as.matrix(dtm)))
txt_mat <- dist(t(as.matrix(dtm)))
lsa_model <- lsa(txt_mat)
s<-matrix(rep(0,16),4,4)
diag(s)<-txt_mat$sk
d<-dist(txt_mat$dk%*%s)
fit5<-hclust(d=d, method="ward.D")
lsa_model <- Isa(txt_mat)
lsa_model <- isa(txt_mat)
lsa_model <- isa(txt_mat)
install.packages("lsa")
txt_mat <- as.textmatrix(t(as.matrix(dtm)))
txt_mat <- dist(t(as.matrix(dtm)))
lsa_model <- lsa(txt_mat)
install.packages("lsa")
lsa_model <- lsa(txt_mat)
txt_mat <- as.textmatrix(t(as.matrix(dtm)))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("lda")
runApp()
install.packages("topicmodels")
install.packages("topicmodels")
shiny::runApp()
remove.packages("topicmodels")
runApp()
install.packages("http://cran.r-project.org/bin/windows/contrib/3.0/tm_0.5-10.zip",repos=NULL)
runApp()
shiny::runApp()
install.packages("http://cran.r-project.org/bin/windows/contrib/3.0/tm_0.5-10.zip",repos=NULL)
runApp()
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("tmap")
install.packages("SnowballC")
runApp()
detach("package:RColorBrewer", unload=TRUE)
library("RColorBrewer", lib.loc="c:/Program Files/R/R/library")
install.packages("RColorBrewer")
shiny::runApp()
install.packages("lsa")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("lda")
install.packages("ldamatch")
runApp()
shiny::runApp()
